#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ’æœŸå®¡æ ¸æŠ¥å‘Šç”Ÿæˆå™¨ - åŸºäº audit_results.json ç”Ÿæˆ markdown æŠ¥å‘Š
ç”¨æ³•: python report_generator.py --input <audit_results.json> --output <æŠ¥å‘Š.md> --holiday <èŠ‚æ—¥å>
"""
import argparse
import json
import os
from datetime import datetime


def generate_report(data, holiday_name='èŠ‚æ—¥'):
    """ç”Ÿæˆ markdown æ ¼å¼çš„å®¡æ ¸æŠ¥å‘Š"""
    lines = []
    meta = data['meta']
    matching = data['activity_matching']
    time_comp = data['time_comparison']
    server_comp = data['server_comparison']
    naming = data['naming_issues']

    # æ ‡é¢˜
    lines.append(f'# {holiday_name}æ´»åŠ¨ - æ’æœŸå®¡æ ¸ vs æ­£å¼ä¸Šçº¿ æ€»ç»“æŠ¥å‘Š')
    lines.append('')
    lines.append(f'> å®¡æ ¸æ—¥æœŸï¼š{meta["audit_date"]}')
    lines.append(f'> æ•°æ®æ¥æºï¼šæ’æœŸå®¡æ ¸è¡¨(xlsx) vs æ­£å¼ä¸Šçº¿è¡¨(csv)')
    lines.append('')
    lines.append('---')
    lines.append('')

    # ä¸€ã€æ€»è§ˆ
    lines.append('## ä¸€ã€æ€»è§ˆ')
    lines.append('')
    lines.append('| ç»´åº¦ | æ’æœŸå®¡æ ¸è¡¨ | æ­£å¼ä¸Šçº¿è¡¨ | è¯´æ˜ |')
    lines.append('|------|-----------|-----------|------|')
    lines.append(f'| æ´»åŠ¨æ•° | {meta["xlsx_activity_count"]}é¡¹ | '
                 f'{meta["csv_total_records"]}æ¡è®°å½•(å»é‡å{meta["csv_unique_names"]}ä¸ªå”¯ä¸€æ´»åŠ¨å) | '
                 f'ä¸Šçº¿è¡¨å«å¤šæœŸæ‹†åˆ† |')
    ref = meta.get('ref_server_sets', {})
    lines.append(f'| æœåŠ¡å™¨ | å…¨æœ{ref.get("full", "?")} / å«ç°åº¦? | '
                 f'S6:{ref.get("s6", "?")} + S3-5:{ref.get("s35", "?")} = '
                 f'{ref.get("s6", 0) + ref.get("s35", 0)}(å…¨æœ) | |')
    lines.append('')
    lines.append('---')
    lines.append('')

    # äºŒã€æ´»åŠ¨æ¡ç›®åŒ¹é…
    lines.append(f'## äºŒã€æ´»åŠ¨æ¡ç›®åŒ¹é…ï¼ˆ{meta["xlsx_activity_count"]}é¡¹æ’æœŸ vs ä¸Šçº¿è¡¨ï¼‰')
    lines.append('')

    # å·²åŒ¹é…
    lines.append(f'### âœ… å·²åŒ¹é…ï¼š{matching["matched_count"]}é¡¹')
    lines.append('')
    if matching['matched']:
        lines.append('| # | æ’æœŸå®¡æ ¸è¡¨ | è´Ÿè´£äºº | æ­£å¼ä¸Šçº¿è¡¨ | ä¸Šçº¿æ¡æ•° |')
        lines.append('|---|-----------|--------|-----------|---------|')
        for i, m in enumerate(matching['matched'], 1):
            csv_desc = _format_csv_items(m['csv_items'])
            lines.append(f'| {i} | {m["xlsx_name"]} | {m["person"]} | {csv_desc} | {m["csv_count"]} |')
        lines.append('')

    # æ’æœŸæœ‰ä½†ä¸Šçº¿ç¼ºå¤±
    if matching['xlsx_missing']:
        lines.append(f'### âŒ æ’æœŸè¡¨æœ‰ä½†ä¸Šçº¿è¡¨ç¼ºå¤±ï¼š{matching["xlsx_missing_count"]}é¡¹')
        lines.append('')
        lines.append('| # | æ´»åŠ¨ | è´Ÿè´£äºº | è¯´æ˜ |')
        lines.append('|---|------|--------|------|')
        for i, m in enumerate(matching['xlsx_missing'], 1):
            lines.append(f'| {i} | **{m["name"]}** | {m["person"]} | {m["note"]} |')
        lines.append('')

    # ä¸Šçº¿æœ‰ä½†æ’æœŸç¼ºå¤±
    if matching['csv_missing']:
        lines.append(f'### âŒ ä¸Šçº¿è¡¨æœ‰ä½†æ’æœŸè¡¨ç¼ºå¤±ï¼š{matching["csv_missing_count"]}é¡¹')
        lines.append('')
        lines.append('| æ´»åŠ¨ | ä¸Šçº¿æ¡æ•° | æ´»åŠ¨ID | è¯´æ˜ |')
        lines.append('|------|---------|--------|------|')
        for m in matching['csv_missing']:
            ids_str = '/'.join(str(i) for i in m['ids'][:5])
            if len(m['ids']) > 5:
                ids_str += '...'
            lines.append(f'| **{m["name"]}** | {m["count"]}æ¡ | {ids_str} | æ’æœŸè¡¨æ— æ­¤æ´»åŠ¨ |')
        lines.append('')

    lines.append('---')
    lines.append('')

    # ä¸‰ã€ä¸Šçº¿æ—¶é—´å¯¹æ¯”
    lines.append('## ä¸‰ã€ä¸Šçº¿æ—¶é—´å¯¹æ¯”')
    lines.append('')
    lines.append('### è§„å¾‹å‘ç°')
    lines.append('')
    lines.append(f'æ’æœŸæ ‡è®°æ—¥ = éƒ¨ç½²æ“ä½œæ—¥ï¼Œå®é™…ä¸Šçº¿ = æ ‡è®°æ—¥ {time_comp["offset_pattern"]}')
    lines.append('')

    if time_comp['with_marks']:
        lines.append('### æœ‰æ—¥æœŸæ ‡è®°çš„æ´»åŠ¨é€æœŸæ¯”å¯¹')
        lines.append('')
        for item in time_comp['with_marks']:
            lines.append(f'#### {item["xlsx_name"]}ï¼ˆè´Ÿè´£äºº: {item["person"]}ï¼‰')
            lines.append('')
            lines.append(f'æ’æœŸæ ‡è®°: {", ".join(item["mark_details"])}')
            lines.append('')
            lines.append('| ä¸Šçº¿æ´»åŠ¨ | ID | ä¸Šçº¿æ—¶é—´ | æ—¶é•¿ | æ¯”å¯¹ç»“æœ |')
            lines.append('|---------|-----|---------|------|---------|')
            for c in item['comparisons']:
                start_short = c['csv_start'][:16] if c['csv_start'] else ''
                end_short = c['csv_end'][:16] if c['csv_end'] else ''
                lines.append(f'| {c["csv_name"]} | {c["csv_id"]} | {start_short}~{end_short} | '
                             f'{c["csv_duration"]} | {c["result"]} |')
            lines.append('')

    if time_comp['without_marks']:
        lines.append('### æ— æ—¥æœŸæ ‡è®°çš„æ´»åŠ¨ï¼ˆä»…åˆ—å‡ºä¸Šçº¿æ—¶é—´ï¼‰')
        lines.append('')
        lines.append('| æ’æœŸæ´»åŠ¨ | ä¸Šçº¿æ´»åŠ¨ | ID | ä¸Šçº¿æ—¶é—´ | æ—¶é•¿ |')
        lines.append('|---------|---------|-----|---------|------|')
        for item in time_comp['without_marks']:
            start_short = item['start'][:16] if item['start'] else ''
            end_short = item['end'][:16] if item['end'] else ''
            lines.append(f'| {item["xlsx_name"]} | {item["csv_name"]} | {item["csv_id"]} | '
                         f'{start_short}~{end_short} | {item["duration"]} |')
        lines.append('')

    lines.append('---')
    lines.append('')

    # å››ã€æœåŠ¡å™¨é…ç½®å¯¹æ¯”
    lines.append('## å››ã€æœåŠ¡å™¨é…ç½®å¯¹æ¯”')
    lines.append('')

    if server_comp['cross_type_mismatch']:
        lines.append(f'### è·¨æœç±»å‹ä¸åŒ¹é…ï¼š{len(server_comp["cross_type_mismatch"])}é¡¹')
        lines.append('')
        lines.append('| # | æ’æœŸæ´»åŠ¨ | ä¸Šçº¿æ´»åŠ¨ | æ’æœŸæ ‡æ³¨ | ä¸Šçº¿å®é™… | è¯´æ˜ |')
        lines.append('|---|---------|---------|---------|---------|------|')
        for i, m in enumerate(server_comp['cross_type_mismatch'], 1):
            lines.append(f'| {i} | {m["xlsx_name"]} | {m["csv_name"]} | {m["xlsx_cross"]} | '
                         f'{m["csv_cross"]} | {m["note"]} |')
        lines.append('')

    if server_comp['server_count_issues']:
        lines.append(f'### æœåŠ¡å™¨æ•°é‡å¼‚å¸¸ï¼š{len(server_comp["server_count_issues"])}é¡¹')
        lines.append('')
        lines.append('| # | æ´»åŠ¨ | ID | é¢„æœŸ | å®é™… | å·®å¼‚ | è¯´æ˜ |')
        lines.append('|---|------|----|------|------|------|------|')
        for i, m in enumerate(server_comp['server_count_issues'], 1):
            lines.append(f'| {i} | {m["csv_name"]} | {m["csv_id"]} | {m["expected"]} | '
                         f'{m["actual"]} | {m["diff"]:+d} | {m["note"]} |')
        lines.append('')

    if server_comp['schema_split_check']:
        all_ok = all(s['ok'] for s in server_comp['schema_split_check'])
        status = 'å…¨éƒ¨é€šè¿‡ âœ…' if all_ok else 'å­˜åœ¨é—®é¢˜ âŒ'
        lines.append(f'### Schema åˆ†å‰²å®Œæ•´æ€§ï¼š{status}')
        lines.append('')
        lines.append('| Schema6 æ´»åŠ¨ | Schema3-5 æ´»åŠ¨ | S6æœåŠ¡å™¨ | S35æœåŠ¡å™¨ | åˆè®¡ | é‡å  | ç»“æœ |')
        lines.append('|-------------|---------------|---------|----------|------|------|------|')
        for s in server_comp['schema_split_check']:
            result = 'âœ… æ— é‡å ' if s['ok'] else f'âŒ é‡å {s["overlap"]}ä¸ª'
            lines.append(f'| {s["s6_name"]} | {s["s35_name"]} | {s["s6_count"]} | '
                         f'{s["s35_count"]} | {s["combined"]} | {s["overlap"]} | {result} |')
        lines.append('')

    lines.append('---')
    lines.append('')

    # äº”ã€æ´»åŠ¨å‘½åé—®é¢˜
    if naming:
        lines.append('## äº”ã€æ´»åŠ¨å‘½åé—®é¢˜')
        lines.append('')
        lines.append('| ä¸Šçº¿è¡¨æ´»åŠ¨å | ID | é—®é¢˜ |')
        lines.append('|-------------|-----|------|')
        for n in naming:
            ids_str = '/'.join(str(i) for i in n['ids'][:3])
            lines.append(f'| **{n["csv_name"]}** | {ids_str} | {n["issue"]} |')
        lines.append('')
        lines.append('---')
        lines.append('')

    # å…­ã€å¾…ç¡®è®¤äº‹é¡¹æ¸…å•
    lines.append('## å…­ã€å¾…ç¡®è®¤äº‹é¡¹æ¸…å•')
    lines.append('')
    todo_items = _generate_todo_list(matching, server_comp, naming)
    if todo_items:
        lines.append('| åºå· | ä¼˜å…ˆçº§ | äº‹é¡¹ | è¯´æ˜ |')
        lines.append('|------|--------|------|------|')
        for i, t in enumerate(todo_items, 1):
            lines.append(f'| {i} | {t["priority"]} | {t["item"]} | {t["note"]} |')
    else:
        lines.append('æ— å¾…ç¡®è®¤äº‹é¡¹ã€‚')
    lines.append('')

    return '\n'.join(lines)


def _format_csv_items(items):
    """æ ¼å¼åŒ– CSV åŒ¹é…é¡¹ç›®"""
    if len(items) <= 2:
        return ' + '.join(f'{it["csv_name"]}({it["id"]})' for it in items)
    else:
        first = f'{items[0]["csv_name"]}({items[0]["id"]})'
        return f'{first} ç­‰{len(items)}æ¡'


def _generate_todo_list(matching, server_comp, naming):
    """è‡ªåŠ¨ç”Ÿæˆå¾…ç¡®è®¤äº‹é¡¹"""
    todos = []

    # é«˜ä¼˜å…ˆçº§ï¼šæ’æœŸè¡¨æœ‰ä½†ä¸Šçº¿ç¼ºå¤±
    for m in matching['xlsx_missing']:
        todos.append({
            'priority': 'ğŸ”´é«˜',
            'item': f'**{m["name"]}** æ’æœŸè¡¨æœ‰ä½†ä¸Šçº¿è¡¨ç¼ºå¤±',
            'note': m['note'],
        })

    # é«˜ä¼˜å…ˆçº§ï¼šä¸Šçº¿æœ‰ä½†æ’æœŸç¼ºå¤±
    for m in matching['csv_missing']:
        if m['count'] >= 3:  # å¤šæ¡è®°å½•æ›´ä¸¥é‡
            todos.append({
                'priority': 'ğŸ”´é«˜',
                'item': f'**{m["name"]}** ({m["count"]}æ¡) ä¸Šçº¿è¡¨æœ‰ä½†æ’æœŸè¡¨ç¼ºå¤±',
                'note': 'æ˜¯å¦é—æ¼å®¡æ ¸ï¼Ÿ',
            })

    # ä¸­ä¼˜å…ˆçº§ï¼šè·¨æœç±»å‹ä¸åŒ¹é…
    if server_comp['cross_type_mismatch']:
        todos.append({
            'priority': 'ğŸŸ¡ä¸­',
            'item': f'{len(server_comp["cross_type_mismatch"])}é¡¹æ´»åŠ¨**è·¨æœç±»å‹ä¸åŒ¹é…**',
            'note': 'ç¡®è®¤æ’æœŸè¡¨æè¿°æˆ–ä¸Šçº¿é…ç½®å“ªä¸ªæ­£ç¡®',
        })

    # ä¸­ä¼˜å…ˆçº§ï¼šæœåŠ¡å™¨æ•°é‡å¼‚å¸¸
    if server_comp['server_count_issues']:
        todos.append({
            'priority': 'ğŸŸ¡ä¸­',
            'item': f'{len(server_comp["server_count_issues"])}é¡¹æ´»åŠ¨**æœåŠ¡å™¨æ•°é‡å¼‚å¸¸**',
            'note': 'ç¡®è®¤æ˜¯å¦æœ‰æ„ä¸ºä¹‹',
        })

    # ä½ä¼˜å…ˆçº§ï¼šå‘½åé—®é¢˜
    if naming:
        todos.append({
            'priority': 'ğŸŸ¢ä½',
            'item': f'{len(naming)}ä¸ªæ´»åŠ¨åç§°å¯èƒ½æœ‰è¯¯',
            'note': 'æ²¿ç”¨æ—§èŠ‚æ—¥åç§°æˆ–å¹´ä»½é”™è¯¯',
        })

    return todos


def main():
    parser = argparse.ArgumentParser(description='æ’æœŸå®¡æ ¸æŠ¥å‘Šç”Ÿæˆå™¨')
    parser.add_argument('--input', required=True, help='audit_results.json è·¯å¾„')
    parser.add_argument('--output', required=True, help='è¾“å‡ºæŠ¥å‘Šè·¯å¾„(.md)')
    parser.add_argument('--holiday', default='èŠ‚æ—¥', help='èŠ‚æ—¥åç§°ï¼ˆå¦‚"2026æƒ…äººèŠ‚"ï¼‰')
    args = parser.parse_args()

    with open(args.input, 'r', encoding='utf-8') as f:
        data = json.load(f)

    report = generate_report(data, args.holiday)

    with open(args.output, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f'æŠ¥å‘Šå·²ç”Ÿæˆ: {args.output}')


if __name__ == '__main__':
    main()
